---
title: "What a Customer Panel Reinforced About Vulnerability Prioritization"
categories:
  - Reflections
tags:
  - Speaking
  - Prioritization
excerpt: "Security teams aren’t short on vulnerability data, they’re short on context and repeatable decision-making, and that’s where transparent prioritization and automation make the difference."
---

I recently participated in a customer panel hosted by a security vendor my team heavily relies on. The audience included public and private sector practitioners across vulnerability management, cloud security, and GRC. The goal of the session was to connect customers and share practical approaches for using the platform to drive measurable outcomes.

## Topics I covered:
- What I learned early in my career from manually massaging 10,000+ rows of raw data (and why that work still happens today in many organizations)
- How automation changes the remediation lifecycle: from prioritization to stakeholder communication
- Tradeoffs between vendor-native and vendor-agnostic prioritization
- How transparency in your process can create space for better collaboration (security, IT, engineering, and leadership)

What stood out most was the Q&A. A large number of people asked variations of the same questions: What inputs should we include in prioritization? How do you choose weights/values? Where do you start when everything feels urgent? None of this is new, but the volume and consistency of the questions reinforced something I see often: security teams are overloaded with findings, but under-supported on ways to add context and make decisions consistently.

## What I’d do differently next time
- **Bring a simple starter model.** A one-slide example prioritization rubric (e.g., exploitability + asset criticality + exposure + compensating controls) so people can leave with a baseline they can implement.
- **Show a before/after workflow.** One concrete example of how a finding moves from intake > prioritization > validation > metrics; including where automation reduces friction.
- **Clarify the tradeoffs earlier.** Lead with when vendor-native is “good enough” vs. when vendor-agnostic is worth the extra tooling/effort, so the audience can immediately come to a decision
- **Leave time for implementation questions.** More of the audience seemed stuck on how to start than why it matters

If you feel like you’re drowning in vulnerabilities and can’t consistently meet SLAs, it’s usually not a motivation problem, but a context and decision making problem. Start small by defining a lightweight prioritization model, make it transparent, and automate where possible. The goal isn’t perfect scoring, but repeating decisions that scale and can be improved over time.